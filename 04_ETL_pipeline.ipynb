{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf12304",
   "metadata": {},
   "source": [
    "Kelompok 6:\n",
    "- Fawwas Aliy 235150300111009\n",
    "- Briliiant Akhmad Assiddiqqy 235150301111045\n",
    "- Andan Riski Mustari 235150301111002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdb38d2",
   "metadata": {},
   "source": [
    "## ETL Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc74ed4",
   "metadata": {},
   "source": [
    "Membangun pipeline ETL sederhana dari JSON ke CSV. Prosesnya mencakup extract dan flatten data JSON, transform dengan konversi suhu ke Fahrenheit serta perhitungan comfort index, lalu load hasil ke file CSV. Soal ini menilai pemahaman alur pemrosesan data mentah."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a7a12e",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e648f3ad",
   "metadata": {},
   "source": [
    "Impor library yang dibutuhkan yaitu pandas untuk mengelola data dan json untuk membaca data json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a0e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d0bf8",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2126d16d",
   "metadata": {},
   "source": [
    "Fungsi berupa Extract, Transform, dan Load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bdd534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_data(file_path):\n",
    "    # baca file sensor\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # baca nested array\n",
    "    rows = []\n",
    "    for sensor in data:\n",
    "        sensor_id = sensor[\"sensor_id\"]\n",
    "        truck_id = sensor[\"truck_id\"]\n",
    "        for reading in sensor[\"readings\"]:\n",
    "            rows.append({\n",
    "                \"sensor_id\": sensor_id,\n",
    "                \"truck_id\": truck_id,\n",
    "                \"timestamp\": reading[\"timestamp\"],\n",
    "                \"temp\": reading[\"temp\"],\n",
    "                \"humidity\": reading[\"humidity\"]\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "def transform_data(df):\n",
    "    # ubah celsius ke fahrenheit\n",
    "    df[\"temp\"] = df[\"temp\"] * 9/5 + 32\n",
    "\n",
    "    # kalkulasi comfort index\n",
    "    df[\"comfort_index\"] = (df[\"temp\"] / df[\"humidity\"]) * 100\n",
    "    df = df.round({\"temp\": 2, \"comfort_index\": 2})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_to_csv(df, output_path):\n",
    "    # simpan ke path output\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Data berhasil disimpan ke {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9614b5d",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f189e1c",
   "metadata": {},
   "source": [
    "Ambil raw data pada datasets/sensors_2024-10-13.json dan extract data tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a8b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sensor_id truck_id             timestamp  temp  humidity\n",
      "0   SENS001   TRK001  2024-10-13T08:00:00Z  25.0      65.0\n",
      "1   SENS001   TRK001  2024-10-13T08:15:00Z  28.1      67.0\n",
      "2   SENS001   TRK001  2024-10-13T08:30:00Z  26.7      66.0\n",
      "3   SENS002   TRK002  2024-10-13T08:00:00Z   NaN      70.0\n",
      "4   SENS002   TRK002  2024-10-13T08:15:00Z  22.3       NaN\n"
     ]
    }
   ],
   "source": [
    "raw_data = extract_json_data('datasets/sensors_2024-10-13.json')\n",
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ca882",
   "metadata": {},
   "source": [
    "Setelah di extract, beberapa parameter di transform terlebih dahulu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c9cb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sensor_id truck_id             timestamp   temp  humidity  comfort_index\n",
      "0   SENS001   TRK001  2024-10-13T08:00:00Z  77.00      65.0         118.46\n",
      "1   SENS001   TRK001  2024-10-13T08:15:00Z  82.58      67.0         123.25\n",
      "2   SENS001   TRK001  2024-10-13T08:30:00Z  80.06      66.0         121.30\n",
      "3   SENS002   TRK002  2024-10-13T08:00:00Z    NaN      70.0            NaN\n",
      "4   SENS002   TRK002  2024-10-13T08:15:00Z  72.14       NaN            NaN\n"
     ]
    }
   ],
   "source": [
    "transformed_data = transform_data(raw_data)\n",
    "print(transformed_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d241edd8",
   "metadata": {},
   "source": [
    "Setelah itu output disimpan ke csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2311b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data berhasil disimpan ke etl_oupt.csv\n"
     ]
    }
   ],
   "source": [
    "load_to_csv(transformed_data, 'etl_oupt.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
